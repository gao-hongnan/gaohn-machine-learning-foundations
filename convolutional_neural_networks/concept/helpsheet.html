
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Helpsheet: Convolutional Neural Networks &#8212; Machine Learning Foundations</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script src="../../_static/tabs.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"tex": {"macros": {"X": "\\symbf{X}", "st": "\\mid", "S": "\\Omega", "P": "\\mathbb{P}", "R": "\\mathbb{R}", "v": "\\mathbf{v}", "a": "\\mathbf{a}", "b": "\\mathbf{b}", "c": "\\mathbf{c}", "u": "\\mathbf{u}", "w": "\\mathbf{w}", "x": "\\mathbf{x}", "y": "\\mathbf{y}", "z": "\\mathbf{z}", "0": "\\mathbf{0}", "1": "\\mathbf{1}", "A": "\\mathbf{A}", "B": "\\mathbf{B}", "C": "\\mathbf{C}", "E": "\\mathcal{F}", "lset": "\\left\\{", "rset": "\\right\\}", "lsq": "\\left[", "rsq": "\\right]", "lpar": "\\left(", "rpar": "\\right)", "pmf": "p_X", "cdf": "F_X", "pspace": "(\\Omega, \\mathcal{F}, \\mathbb{P})"}}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Gradient Descent Concept" href="../../optimization/concept/gradient_descent_concept.html" />
    <link rel="prev" title="Introduction" href="../../intro.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Machine Learning Foundations</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Convolutional Neural Networks
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Helpsheet: Convolutional Neural Networks
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Optimization
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../optimization/concept/gradient_descent_concept.html">
   Gradient Descent Concept
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../optimization/implementation/gradient_descent_construction.html">
   Gradient Descent Construction
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  References
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../bibliography/bibliography.html">
   Bibliography
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/gao-hongnan/gaohn-machine-learning-foundations"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/gao-hongnan/gaohn-machine-learning-foundations/issues/new?title=Issue%20on%20page%20%2Fconvolutional_neural_networks/concept/helpsheet.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../_sources/convolutional_neural_networks/concept/helpsheet.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#properties-of-cnns">
   Properties of CNNs
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#cross-correlation">
   Cross Correlation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#filters-and-kernels">
   Filters and Kernels
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#feature-map-and-receptive-field">
   Feature Map and Receptive Field
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#padding">
   Padding
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#stride">
   Stride
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#feature-map-output-dimensions">
   Feature Map (Output) Dimensions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#convolutions-over-volumes">
   Convolutions over Volumes
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary">
   Summary
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#further-readings">
   Further Readings
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Helpsheet: Convolutional Neural Networks</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#properties-of-cnns">
   Properties of CNNs
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#cross-correlation">
   Cross Correlation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#filters-and-kernels">
   Filters and Kernels
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#feature-map-and-receptive-field">
   Feature Map and Receptive Field
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#padding">
   Padding
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#stride">
   Stride
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#feature-map-output-dimensions">
   Feature Map (Output) Dimensions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#convolutions-over-volumes">
   Convolutions over Volumes
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary">
   Summary
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#further-readings">
   Further Readings
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="helpsheet-convolutional-neural-networks">
<h1>Helpsheet: Convolutional Neural Networks<a class="headerlink" href="#helpsheet-convolutional-neural-networks" title="Permalink to this headline">#</a></h1>
<p>Everything here is relevant to 2D convolutional neural networks. Definitions may need to scale up
or down if we are talking about 1D or 3D convolutional neural networks.</p>
<div class="proof definition admonition" id="def_image">
<p class="admonition-title"><span class="caption-number">Definition 1 </span> (Image)</p>
<section class="definition-content" id="proof-content">
<p>We define image <span class="math notranslate nohighlight">\(\X\)</span> of size <span class="math notranslate nohighlight">\(C \times H \times W\)</span> where <span class="math notranslate nohighlight">\(C\)</span> is the number of channels,
<span class="math notranslate nohighlight">\(H\)</span> is the height and <span class="math notranslate nohighlight">\(W\)</span> is the width of the image.</p>
</section>
</div><section id="properties-of-cnns">
<h2>Properties of CNNs<a class="headerlink" href="#properties-of-cnns" title="Permalink to this headline">#</a></h2>
<p>To design a Convolutional Neural Networks, we should bear these properties in mind.</p>
<div class="proof property admonition" id="def_translational_invariance">
<p class="admonition-title"><span class="caption-number">Property 1 </span> (Translational Invariance/Translational Equivariance)</p>
<section class="property-content" id="proof-content">
<p>In the earliest layers, our network should respond similarly to the same patch, regardless of where it appears in the image. This principle is called translation invariance (or translation equivariance) <span id="id1">[<a class="reference internal" href="../../bibliography/bibliography.html#id2" title="Aston Zhang, Zachary C. Lipton, Mu Li, and Alexander J. Smola. Dive into Deep Learning. The authors, 2021.">Zhang <em>et al.</em>, 2021</a>]</span>.</p>
<p>This is why we often say the earlier layers of a CNN detects shapes and edges.</p>
</section>
</div><div class="proof property admonition" id="def_locality">
<p class="admonition-title"><span class="caption-number">Property 2 </span> (Locality)</p>
<section class="property-content" id="proof-content">
<p>The earliest layers of the network should focus on local regions, without regard for the contents of the image in distant regions. This is the locality principle. Eventually, these local representations can be aggregated to make predictions at the whole image level <span id="id2">[<a class="reference internal" href="../../bibliography/bibliography.html#id2" title="Aston Zhang, Zachary C. Lipton, Mu Li, and Alexander J. Smola. Dive into Deep Learning. The authors, 2021.">Zhang <em>et al.</em>, 2021</a>]</span>.</p>
</section>
</div><div class="proof property admonition" id="def_abstractness">
<p class="admonition-title"><span class="caption-number">Property 3 </span> (Abstractness)</p>
<section class="property-content" id="proof-content">
<p>As we move deeper into the network, the representations should become more abstract and less sensitive to the exact location of objects in the image. This is the abstractness principle.</p>
</section>
</div><div class="proof property admonition" id="def_parameter_sharing">
<p class="admonition-title"><span class="caption-number">Property 4 </span> (Parameter/Weight Sharing)</p>
<section class="property-content" id="proof-content">
<p>CNNs share parameters across space. This allows the network to learn features that are useful in multiple locations. This is the parameter sharing principle.</p>
<p>One can imagine that the first few layers are detecting shapes and edges, and therefore this same edge detector
will still be useful as move deeper into the network. Therefore, we can say we are sharing parameters across space.</p>
</section>
</div><div class="proof remark admonition" id="def_cnn_properties_remark">
<p class="admonition-title"><span class="caption-number">Remark 1 </span> (Further Reading)</p>
<section class="remark-content" id="proof-content">
<p>Note that we are being loose with terms such as Translational Invariance and Translational Equivariance.
One can read more about them <a class="reference external" href="https://datascience.stackexchange.com/questions/16060/what-is-the-difference-between-equivariant-to-translation-and-invariant-to-tr#:~:text=Equivariant%20to%20translation%20means%20that,an%20equivalent%20translation%20of%20outputs.">here</a> and <a class="reference external" href="https://towardsdatascience.com/translational-invariance-vs-translational-equivariance-f9fbc8fca63a">here</a>.</p>
</section>
</div></section>
<section id="cross-correlation">
<h2>Cross Correlation<a class="headerlink" href="#cross-correlation" title="Permalink to this headline">#</a></h2>
<div class="proof definition admonition" id="def_cross_correlation">
<p class="admonition-title"><span class="caption-number">Definition 2 </span> (Cross Correlation)</p>
<section class="definition-content" id="proof-content">
<p><span class="math notranslate nohighlight">\(\X\)</span></p>
</section>
</div><figure class="align-default" id="fig-cross-correlation">
<img alt="https://storage.googleapis.com/reighns/reighns_ml_projects/docs/gaohn-machine-learning-foundations/correlation_d2l.svg" src="https://storage.googleapis.com/reighns/reighns_ml_projects/docs/gaohn-machine-learning-foundations/correlation_d2l.svg" /><figcaption>
<p><span class="caption-number">Fig. 1 </span><span class="caption-text">Two-dimensional cross-correlation operation. The shaded portions are the first output element as well as the input and kernel tensor elements used for the output computation:
<span class="math notranslate nohighlight">\(0 \times 0 + 1 \times 1 + 3 \times 2 + 4 \times 3 = 19\)</span>.</span><a class="headerlink" href="#fig-cross-correlation" title="Permalink to this image">#</a></p>
<div class="legend">
<p>Image Credits: <a class="reference external" href="https://d2l.ai/chapter_convolutional-neural-networks/conv-layer.html">Dive into Deep Learning</a></p>
</div>
</figcaption>
</figure>
</section>
<section id="filters-and-kernels">
<h2>Filters and Kernels<a class="headerlink" href="#filters-and-kernels" title="Permalink to this headline">#</a></h2>
<div class="proof definition admonition" id="def_kernel">
<p class="admonition-title"><span class="caption-number">Definition 3 </span> (Kernel)</p>
<section class="definition-content" id="proof-content">
<p>A <strong>kernel</strong> is a 2D matrix that is used to extract features from an image <span class="math notranslate nohighlight">\(\X\)</span>.</p>
<p>Although no strict restrictions on the kernel size, the kernel is typically a square
of size <span class="math notranslate nohighlight">\(K \times K\)</span>.</p>
</section>
</div><div class="proof definition admonition" id="def_filter">
<p class="admonition-title"><span class="caption-number">Definition 4 </span> (Filter)</p>
<section class="definition-content" id="proof-content">
<p>A <strong>filter</strong> is a 3D matrix that is a collection of kernels stacked together.</p>
<p>A filter is typically of size <span class="math notranslate nohighlight">\(C_{\text{in}} \times K \times K\)</span> where <span class="math notranslate nohighlight">\(C_{\text{in}}\)</span> is the number of channels
in the preceding layer.</p>
</section>
</div><div class="proof definition admonition" id="def_output_size">
<p class="admonition-title"><span class="caption-number">Definition 5 </span> (Output Size)</p>
<section class="definition-content" id="proof-content">
<p>Given an input size of <span class="math notranslate nohighlight">\(n_h \times n_w\)</span>, and its corresponding kernel size to be <span class="math notranslate nohighlight">\(k_h \times k_w\)</span>,
the output size of a convolutional layer is given by the following formula:</p>
<div class="math notranslate nohighlight">
\[
(n_h - k_h + 1) \times (n_w - k_w + 1)
\]</div>
</section>
</div></section>
<section id="feature-map-and-receptive-field">
<h2>Feature Map and Receptive Field<a class="headerlink" href="#feature-map-and-receptive-field" title="Permalink to this headline">#</a></h2>
<div class="proof definition admonition" id="def_feature_map">
<p class="admonition-title"><span class="caption-number">Definition 6 </span> (Feature Map)</p>
<section class="definition-content" id="proof-content">
<p>The output of a convolutional layer is often called a <strong>feature map</strong> <span id="id3">[<a class="reference internal" href="../../bibliography/bibliography.html#id2" title="Aston Zhang, Zachary C. Lipton, Mu Li, and Alexander J. Smola. Dive into Deep Learning. The authors, 2021.">Zhang <em>et al.</em>, 2021</a>]</span>.</p>
<p>The example in <a class="reference internal" href="#fig-cross-correlation"><span class="std std-numref">Fig. 1</span></a> shows the output to be our feature map.</p>
</section>
</div><div class="proof definition admonition" id="def_receptive_field">
<p class="admonition-title"><span class="caption-number">Definition 7 </span> (Receptive Field)</p>
<section class="definition-content" id="proof-content">
<p>In the context of Convolutional Neural Networks, the <strong>receptive field</strong> is the region of the input image that a single neuron in the convolutional layer is connected to.</p>
<p>More concretely, for any element <span class="math notranslate nohighlight">\(x\)</span> in a layer, the receptive field is the region of the input image that contributed to the computation of <span class="math notranslate nohighlight">\(x\)</span> <span id="id4">[<a class="reference internal" href="../../bibliography/bibliography.html#id2" title="Aston Zhang, Zachary C. Lipton, Mu Li, and Alexander J. Smola. Dive into Deep Learning. The authors, 2021.">Zhang <em>et al.</em>, 2021</a>]</span>.</p>
<p>In <a class="reference internal" href="#fig-cross-correlation"><span class="std std-numref">Fig. 1</span></a>, the receptive field of the first element in the output is the shaded region in the input.</p>
</section>
</div></section>
<section id="padding">
<h2>Padding<a class="headerlink" href="#padding" title="Permalink to this headline">#</a></h2>
<p>Notice that the output size defined in <a class="reference internal" href="#def_output_size">Definition 5</a> is smaller than the input size. Therefore,
after numerous convolutional layers, the output size will be very small. Furthermore, the edges
of the image are used much less than the center of the image. We can use padding to fix these issues.</p>
<div class="proof definition admonition" id="def_valid_padding">
<p class="admonition-title"><span class="caption-number">Definition 8 </span> (Valid Padding)</p>
<section class="definition-content" id="proof-content">
<p>Valid padding is when we do not pad the input image.</p>
</section>
</div><div class="proof definition admonition" id="def_same_padding">
<p class="admonition-title"><span class="caption-number">Definition 9 </span> (Same Padding)</p>
<section class="definition-content" id="proof-content">
<p>Same padding is when we pad the input image such that the output size is the same as the input size.
We usually pad with zeros.</p>
<p>Given an image <span class="math notranslate nohighlight">\(\X\)</span> of size <span class="math notranslate nohighlight">\(n_h \times n_w\)</span>, if we pad <span class="math notranslate nohighlight">\(p\)</span> additional cells on each side of the image, then our input image <span class="math notranslate nohighlight">\(\X\)</span> will now have
an input size of <span class="math notranslate nohighlight">\((n_h + 2p) \times (n_w + 2p)\)</span>. If we apply a convolutional layer with a kernel size of <span class="math notranslate nohighlight">\(k_h \times k_w\)</span>,
we end up with an output size of <span class="math notranslate nohighlight">\((n_h + 2p - k_h + 1) \times (n_w + 2p - k_w + 1) = n_h \times n_w\)</span> by <a class="reference internal" href="#def_output_size">Definition 5</a>.</p>
<p>Then, recall our purpose is to pad the input image such that the output size is the same as the input size. Therefore, we can solve for <span class="math notranslate nohighlight">\(p\)</span>:</p>
<div class="math notranslate nohighlight">
\[
n_h + 2p - k_h + 1 = n_h \implies p = \frac{k_h - 1}{2} = \frac{k - 1}{2}
\]</div>
<p>We have assumed that the image and kernel are square in size. If they are not, then we can solve for <span class="math notranslate nohighlight">\(p\)</span> separately for each dimension.
Further, we assumed that <span class="math notranslate nohighlight">\(k_h = k_w\)</span> is odd, if not, we may to apply floor and ceiling to the above formula.</p>
</section>
</div></section>
<section id="stride">
<h2>Stride<a class="headerlink" href="#stride" title="Permalink to this headline">#</a></h2>
<div class="proof definition admonition" id="def_stride">
<p class="admonition-title"><span class="caption-number">Definition 10 </span> (Stride)</p>
<section class="definition-content" id="proof-content">
<p>In the context of Convolutional Neural Networks, the <strong>stride</strong> is the number of pixels we shift the kernel over the image.</p>
</section>
</div></section>
<section id="feature-map-output-dimensions">
<h2>Feature Map (Output) Dimensions<a class="headerlink" href="#feature-map-output-dimensions" title="Permalink to this headline">#</a></h2>
<div class="proof definition admonition" id="def_calculating_output_dimensions">
<p class="admonition-title"><span class="caption-number">Definition 11 </span> (Calculating Output Dimensions)</p>
<section class="definition-content" id="proof-content">
<p>Given an input image <span class="math notranslate nohighlight">\(\X\)</span> of size <span class="math notranslate nohighlight">\(n \times n\)</span>, a kernel of size <span class="math notranslate nohighlight">\(k \times k\)</span>,
a padding of size <span class="math notranslate nohighlight">\(p\)</span>, and a stride of size <span class="math notranslate nohighlight">\(s \times s\)</span>, the output dimensions are given by:</p>
<div class="math notranslate nohighlight">
\[
\lpar \lfloor \frac{n + 2p - k}{s} \rfloor + 1 \rpar \times \lpar \lfloor \frac{n + 2p - k}{s} \rfloor + 1 \rpar
\]</div>
<p>where <span class="math notranslate nohighlight">\(\lfloor x \rfloor\)</span> is the floor function.</p>
</section>
</div></section>
<section id="convolutions-over-volumes">
<h2>Convolutions over Volumes<a class="headerlink" href="#convolutions-over-volumes" title="Permalink to this headline">#</a></h2>
<p>So far we have only discussed convolutions over 2D images. However, we can also apply convolutions over 3D volumes (i.e. RGB images with 3 channels).</p>
<p>For example, we can apply convolutions over a 3D volume of size <span class="math notranslate nohighlight">\(n_h \times n_w \times n_c\)</span> where <span class="math notranslate nohighlight">\(n_c\)</span> is the number of channels. In this case, the kernel is also a 3D volume of size <span class="math notranslate nohighlight">\(k_h \times k_w \times n_c\)</span>.</p>
<link rel="stylesheet" type="text/css" href="https://tikzjax.com/v1/fonts.css">
<script src="https://tikzjax.com/v1/tikzjax.js"></script>
<script type="text/tikz">
  \begin{tikzpicture}[scale=0.5]     \draw (0.5, 0.5) rectangle (3.5, 3.5);     \draw (0.25, 0.25) rectangle (3.25, 3.25); 
    \draw (0, 0) rectangle (3, 3);
    \node at (1.5, -.5) {$6 \times 6$};
    \node (channels) at (6.75, .4) {$3$ channels};
    \draw[->] (channels) to (3.5, .4);
  \end{tikzpicture} 
</script>
</section>
<section id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">#</a></h2>
<div class="proof remark admonition" id="def_learning_filters_remark">
<p class="admonition-title"><span class="caption-number">Remark 2 </span> (Learning Filters)</p>
<section class="remark-content" id="proof-content">
<p>Hand picking kernels and filters can be a tedious task. Instead, we let the CNN learn
the filters and kernels for us. Consequently, all the elements in the filter are learnable parameters.</p>
</section>
</div><div class="proof remark admonition" id="def_filter_size_remark">
<p class="admonition-title"><span class="caption-number">Remark 3 </span> (Filter Size)</p>
<section class="remark-content" id="proof-content">
<p>A common misconception arises when we say that we are using a filter of size, say <span class="math notranslate nohighlight">\(5 \times 5\)</span>.
This <strong>does not mean</strong> the filter is a square of size <span class="math notranslate nohighlight">\(5 \times 5\)</span>, instead, it means the filter is a 3D matrix of size <span class="math notranslate nohighlight">\(C_{\text{in}} \times 5 \times 5\)</span>.</p>
</section>
</div><figure class="align-default" id="fig-filters-and-kernels">
<img alt="https://storage.googleapis.com/reighns/reighns_ml_projects/docs/gaohn-machine-learning-foundations/cs231n-convolutional-demo.gif" src="https://storage.googleapis.com/reighns/reighns_ml_projects/docs/gaohn-machine-learning-foundations/cs231n-convolutional-demo.gif" />
<figcaption>
<p><span class="caption-number">Fig. 2 </span><span class="caption-text">The filter is applied to each region of the input image, and the result is a single value. Image Credit: <a class="reference external" href="https://cs231n.github.io/convolutional-networks/">CS231N</a></span><a class="headerlink" href="#fig-filters-and-kernels" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="further-readings">
<h2>Further Readings<a class="headerlink" href="#further-readings" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>Zhang, Aston, Zachary C. Lipton, Mu Li, and Alexander J. Smola. “Chapter 7. Convolutional Neural Networks.” In Dive into Deep Learning. Berkeley: 2021</p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./convolutional_neural_networks/concept"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="../../intro.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Introduction</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../../optimization/concept/gradient_descent_concept.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Gradient Descent Concept</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Hongnan Gao<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>